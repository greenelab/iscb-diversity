---
title: "Predict race/ethnicity based on census data"
output: html_document
---

## Setups

```{r message = F}
if (!requireNamespace('wru')) install.packages('wru')

library(wru)
library(tidyverse)
library(lubridate)
source('utils/r-utils.R')
```

## Load data
and use the `wru` package to predict race based on last_names only

```{r}
pubmed_race_df <- read_tsv('data/pubmed/authors.tsv.xz') %>%
  filter(reverse_position == 1) %>%
  left_join(read_tsv('data/pubmed/articles.tsv.xz'), by = 'pmid') %>%
  mutate(year = substr(publication_date, 1, 4) %>% ymd(truncated = 2),
         publication_date = ymd(publication_date, truncated = 2)) %>%
  rename('surname' = last_name) %>% 
  predict_race(surname.only = T, impute.missing = F)

iscb_race_df <- read_tsv('data/iscb/keynotes.tsv') %>%
  rename('surname' = last_name) %>%
  mutate(year = ymd(year, truncated = 2)) %>% 
  predict_race(surname.only = T, impute.missing = F)

# unmatched names
iscb_race_df[is.na(iscb_race_df$pred.whi), 1:2]

alpha <- qnorm(0.975)
start_year <- 1997
end_year <- 2020
n_years <- end_year - start_year
my_jours <- unique(pubmed_race_df$journal)
my_confs <- unique(iscb_race_df$Conference)
n_jours <- length(my_jours)
n_confs <- length(my_confs)
race_levels <- c('White', 'Asian', 'Black', 'Hispanic', 'Others', 'All others')
```

Pubmed: 7891 last_names out of 29615 were not matched.
iscb: 82 surnames out of 348 were not matched.

## Descriptive statistics
Prepare data frames for later analyses:

- bind_rows results of race predictions in iscb and Pubmed
- pivot long
- compute mean, sd, marginal error
- add "White" vs. "Others"

```{r}
iscb_pubmed <- iscb_race_df %>%
  rename('journal' = Conference) %>% 
  select(year, journal, contains('pred')) %>%
  mutate(publication_date = year,
         type = 'Keynotes/Fellows',
         pred_sum_others = pred.his + pred.oth + pred.bla) %>%
  bind_rows(
    pubmed_race_df %>%
      select(year, journal, contains('pred'), publication_date) %>%
      mutate(type = 'Pubmed',
             pred_sum_others = pred.his + pred.oth + pred.bla)
  ) %>%
  pivot_longer(contains('pred'),
               names_to = 'Race',
               values_to = 'Probabilities') %>%
  recode_race() %>%
  group_by(type, year, publication_date, Race) %>%
  add_count() %>%
  mutate(
    mean_prob = mean(Probabilities, na.rm = T),
    sd_prob = sd(Probabilities, na.rm = T),
    n = mean(n),
    me_prob = alpha * sd_prob / sqrt(n)
  ) %>%
  ungroup() 

```


## Stacked bar plots:
### By journals:

```{r}
pubmed_race <- vector('list', length = n_jours)
i <- 0

for (jour in my_jours){
  i <- i + 1
  pubmed_race[[i]] <- iscb_pubmed %>%
    filter(type == 'Pubmed' & journal == jour & (Race != 'All others')) %>%
    group_by(year, Race, journal) %>%
    summarise(mean_prob = mean(Probabilities, na.rm = T)) %>%
    ungroup()
}

bind_rows(pubmed_race) %>%
  race_breakdown(start_year + 1, end_year - 1, 'journal')

# The chronologically first journal, Bioinformatics, started in 1998.
# We consider papers up to 2019 right now. (code run on 2020-01-13)
```

What's in Bioinformatics 1999?

```{r}
pubmed_race_df %>% 
  filter(year == '1999-01-01' & !is.na(pred.whi)) %>% 
  select(contains('pred')) %>% 
  colMeans() 

pubmed_race_df %>% 
  filter(year == '1999-01-01' & !is.na(pred.whi)) %>% 
  filter(pred.asi > 0.1) %>% 
  select(fore_name, surname, contains('pred')) 

pubmed_race_df %>% 
  filter(year == '1999-01-01' & !is.na(pred.whi)) %>% 
  filter(pred.his > 0.1) %>% 
  select(fore_name, surname, contains('pred')) 
```

Bioinformatics 1998: `wru` was able to predict 77 out of 121 last authors published that year, and it predicts 10 and 6 authors to have > 0.1 probability of being Asian and Hispanic, respectively, hence what we see.

### By conference keynotes/fellows:

```{r fig.height=6}
iscb_race <- vector('list', length = n_confs)
i <- 0

for (conf in my_confs){
  i <- i + 1
  iscb_race[[i]] <- iscb_pubmed %>%
    filter(type != 'Pubmed' & journal == conf & (Race != 'All others')) %>%
    group_by(year, Race, journal) %>%
    summarise(mean_prob = mean(Probabilities, na.rm = T)) %>%
    ungroup()
}

bind_rows(iscb_race) %>%
  race_breakdown(start_year, end_year, 'journal')
  
```

### All fellows and keynotes compared to three ISCB partner journals:
```{r fig.width=10, fig.height=4}
iscb_pubmed %>%
  filter(Race != 'All others') %>%
  group_by(year, type, Race) %>%
  summarise(mean_prob = mean(Probabilities, na.rm = T)) %>%
  ungroup() %>%
  race_breakdown(start_year, end_year, journal = 'type', facet_by = 'col')
```


```{r fig.width=10}
# boxplot iscb, pubmed faceted by year
iscb_pubmed %>% 
  filter(Race == 'White') %>% 
  ggplot(aes(x = type, fill = type, y = Probabilities)) +
  geom_violin(alpha = 0.8) +
  facet_wrap(~ year(year), nrow = 3) +
  theme_bw() +
  labs(x = NULL, y = 'Probabilities of being white') +
  scale_x_discrete(label = NULL) +
  theme(legend.title = element_blank()) +
  scale_fill_viridis_d()
```



Confidence interval of the mean? (Aggregation)

Null: The proportion of white keynote iscb speakers is not larger the proportions of white last authors published in Pubmed.
Alternative: The proportion of white keynote iscb speakers is larger the proportions of white last authors published in Pubmed.
How do we take time component into account?
Right now, I'm thinking we can use `year` as a random variable.
Perhaps we should allow for random slope as well?

Bootstrap?

```{r fig.width=10, fig.height=4}
get_summary <- function(df){
  df %>% filter(type != 'Pubmed') %>% select(- Probabilities) %>% distinct()
}

ggplot(iscb_pubmed %>% filter(Race == 'White' | Race == 'Asian' | Race == 'All others'),
       aes(x = year)) +
  facet_grid(cols = vars(fct_rev(Race))) +
  geom_smooth(aes(x = publication_date, y = Probabilities, color = type, fill = type)) +
  geom_point(
    data = . %>% filter(type != 'Pubmed'),
    aes(y = Probabilities, color = type),
    alpha = 0.2,
    show.legend = F
  ) +
  geom_point(
    data = . %>% get_summary(),
    aes(y = mean_prob, color = type),
    shape = 2,
    alpha = 0.5,
    show.legend = F
  ) +
  geom_linerange(
    data = . %>% get_summary(),
    aes(
      ymin = mean_prob - me_prob,
      ymax = mean_prob + me_prob,
      color = type
    ),
    alpha = 0.5,
    show.legend = F
  ) +
  theme_bw() +
  scale_y_continuous(breaks = seq(0, 1, 0.2)) +
  theme(legend.title = element_blank()) +
  scale_color_viridis_d(option = 'E') +
  scale_fill_viridis_d(option = 'E') +
  coord_cartesian(ylim = c(0, 1)) +
  labs(x = NULL)

```

Here, each point is a name.

```{r}
# Check: probabilities, if valid, should add up to 1
iscb_pubmed %>%
  filter(Race == 'White' | Race == 'Asian' | Race == 'All others') %>% 
  group_by(type, year, publication_date, Race) %>%
  summarise(mean_prob = mean(Probabilities, na.rm = T)) %>%
  summarise(all_prob = sum(mean_prob))
```

